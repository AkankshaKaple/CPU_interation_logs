{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns; sns.set(style='white')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "data = pd.read_csv('/home/administrator123/Akanksha/Company_Work/datasetcpulogs/Data/CpuLogData.csv')\n",
    "# data = pd.read_csv('https://raw.githubusercontent.com/prayas2409/logs/master/CpuLogData.csv')\n",
    "data['Dates'] = pd.to_datetime(data['DateTime']).dt.date\n",
    "data['Time'] = pd.to_datetime(data['DateTime']).dt.time\n",
    "\n",
    "\n",
    "u_name = ['mohitkr1301@gmail.com', 'sapnapatil344@gmail.com', 'akankshakaple@gmail.com'\n",
    "         ,'you@example.com', 'honeykrsingh16@gmail.com', 'kiranraikar777@gmail.com'\n",
    "          , 'kadamsagar039@gmail.com', 'singh.saurabh3333@gmail.com']\n",
    "for i in u_name:\n",
    "    data.drop(data[data['user_name'] == i].index, inplace=True)\n",
    "\n",
    "    \n",
    "feature_eng_col = ['Cpu Working Time', 'Cpu idle Time', 'number of software interrupts since boot'\n",
    "                   ,'number of interrupts since boot', 'disk_read_count', 'disk_write_count'\n",
    "                   ,'disk_read_bytes', 'disk_write_bytes', 'time spent reading from disk'\n",
    "                   ,'time spent writing to disk', 'time spent doing actual I/Os'\n",
    "                   ,'number of bytes sent', 'number of bytes received'\n",
    "                   ,'number of packets sent', 'number of packets recived']\n",
    "\n",
    "# To be checked again\n",
    "\n",
    "# Remove constant data\n",
    "constant_col = ['Cpu Count', 'Usage Cpu Count ', 'number of system calls since boot'\n",
    "                , 'system_total_memory', 'total number of errors while receiving'\n",
    "                ,'total number of errors while sending','total number of incoming packets which were dropped'\n",
    "                ,'total number of outgoing packets which were dropped', 'disk_total_memory']\n",
    "\n",
    "# Remove Inter dependent data\n",
    "inter_dependet_cols = ['system_free_memory', 'disk_free_memory', 'system_avalible_memory', 'system_used_memory']\n",
    "\n",
    "# Remove object data \n",
    "object_col = ['DateTime', 'Dates', 'Time', 'boot_time']\n",
    "\n",
    "def remove_col(data,col_list):\n",
    "    data.drop(columns=col_list, inplace=True)\n",
    "    return data\n",
    "data = remove_col(data, inter_dependet_cols)\n",
    "# data.columns\n",
    "data = remove_col(data, constant_col)\n",
    "\n",
    "def feature_engineering(feature_eng_col, data):    \n",
    "    user_name = data['user_name'].unique()\n",
    "    final_df = pd.DataFrame()\n",
    "    # print(user_name)\n",
    "    for u_name in user_name:\n",
    "        df = data[data['user_name'] == u_name]\n",
    "        df.sort_values('DateTime', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        for col in feature_eng_col:\n",
    "            l1 =[]\n",
    "            l1.append(df[col].iloc[0])\n",
    "            for index in range(1,len(df)):\n",
    "\n",
    "                if (df[\"Dates\"].iloc[index] == df[\"Dates\"].iloc[index-1]):\n",
    "                    # As when curr smaller than prev\n",
    "                    if (df[col].iloc[index]-df[col].iloc[index-1]) <= 0:\n",
    "                        l1.append(df[col].iloc[index])\n",
    "                        # curr > prev\n",
    "                    elif (df[col].iloc[index]-df[col].iloc[index-1]) > 0:\n",
    "                        l1.append(df[col].iloc[index]-df[col].iloc[index-1])\n",
    "\n",
    "                else:\n",
    "                    l1.append(df[col].iloc[index])\n",
    "            df[col+\"_fe\"]=l1\n",
    "        final_df = final_df.append(df)\n",
    "        for col in feature_eng_col:\n",
    "            final_df.drop(columns=col, inplace=True)\n",
    "    return final_df\n",
    "\n",
    "final_df = feature_engineering(feature_eng_col, data)\n",
    "\n",
    "data.shape, final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "def std(data):\n",
    "    # standardize the data attributes\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object':\n",
    "            data = data.drop(columns=col)\n",
    "    sc = StandardScaler()\n",
    "    standardized_X = sc.fit_transform(data)\n",
    "    new_data = pd.DataFrame(standardized_X, columns=data.columns)\n",
    "    \n",
    "    return new_data\n",
    "new_data = std(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Dates'] = list(final_df['Dates'])\n",
    "new_data['user_name'] = list(final_df['user_name'])\n",
    "new_data['Time'] = list(final_df['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data.user_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = (np.sqrt((df['Humidity'])))\n",
    "# print ('Skewness is', target.skew())\n",
    "# sns.distplot(target)\n",
    "# new_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(data):\n",
    "    dt = data[data['user_name']=='sheetalbedarkar96@gmail.com']\n",
    "    dt2 = dt[dt['Dates']==dt['Dates'].unique()[2]]\n",
    "    \n",
    "    for i in range(1,len(dt2.columns)):\n",
    "        if final_df[dt2.columns[i]].dtype != 'object':\n",
    "            print(dt2.columns[i])\n",
    "#             plt.figure(figsize=(15,7))\n",
    "            sb.lineplot(x='Time', y=dt2.columns[i], data=dt2)\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.show()\n",
    "        \n",
    "visualization(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in final_df.columns:\n",
    "#     if final_df[col].dtypes == 'object':\n",
    "#         final_df.drop(columns=col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the outlier from the whole dataset\n",
    "# def remove_outlier(df):\n",
    "#     low = .20\n",
    "#     high = .80\n",
    "#     quant_df = df.quantile([low, high])\n",
    "#     for name in list(df.columns):\n",
    "#         if is_numeric_dtype(df[name]):\n",
    "#             df = df[(df[name] > quant_df.loc[low, name]) & (df[name] < quant_df.loc[high, name])]\n",
    "#     return df\n",
    "\n",
    "# df= remove_outlier(final_df)\n",
    "# # sb.boxplot(df)\n",
    "# plt.figure(figsize=(15,7))\n",
    "# # plt.xticks(rotation='vertical')\n",
    "# s = df.boxplot()\n",
    "# s.set_xticklabels(df.columns,rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler \n",
    "# def std(data):\n",
    "#     # standardize the data attributes\n",
    "#     for col in data.columns:\n",
    "#         if data[col].dtype == 'object':\n",
    "#             data = data.drop(columns=col)\n",
    "#     sc = StandardScaler()\n",
    "#     standardized_X = sc.fit_transform(data)\n",
    "#     new_data = pd.DataFrame(standardized_X, columns=data.columns)\n",
    "    \n",
    "#     return new_data\n",
    "# new_data = std(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# wcss = []\n",
    "\n",
    "# X = np.array(new_data)\n",
    "\n",
    "# for i in range(1, 11):\n",
    "#     kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
    "#     kmeans.fit(X.reshape(-1,1))\n",
    "#     wcss.append(kmeans.inertia_)\n",
    "# plt.plot(range(1, 11), wcss)\n",
    "# plt.title('The Elbow Method')\n",
    "# plt.xlabel('Number of clusters')\n",
    "# plt.ylabel('WCSS')\n",
    "# plt.show()\n",
    "\n",
    "# kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)\n",
    "# y_kmeans = kmeans.fit_predict(new_data)\n",
    "# new_data['y'] = y_kmeans\n",
    "\n",
    "# sb.countplot(x=y_kmeans, data=new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sb.boxplot(final_df)\n",
    "# from pandas.api.types import is_numeric_dtype\n",
    "# def remove_outlier(df, name):\n",
    "#     low = .25\n",
    "#     high = .75\n",
    "#     quant_df = df.quantile([low, high])\n",
    "# #     for name in list(df.columns):\n",
    "# #         if is_numeric_dtype(df[name]):\n",
    "#     for i in range(len(df)):\n",
    "#         if df[name].iloc[i]  > quant_df.loc[low, name] or df[name].iloc[i] < quant_df.loc[high, name]:\n",
    "# #             print(df[name].iloc[i])\n",
    "#             df[name].iloc[i] = np.average(df[name])\n",
    "# #             print(df[name].iloc[i])\n",
    "#     return df\n",
    "# l = ['system_active_memory','disk_used_memory','system_inactive_memory','system_buffers_memory',\n",
    "#        'system_cached_memory','system_shared_memory']\n",
    "# # for i in l:\n",
    "# #     print(i)\n",
    "# df= remove_outlier(new_data,'system_active_memory')\n",
    "# #     sb.boxplot(df)\n",
    "# plt.figure(figsize=(15,7))\n",
    "# plt.xticks(rotation='vertical')\n",
    "# s = df.boxplot()\n",
    "# s.set_xticklabels(df.columns,rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low = .20\n",
    "# high = .80\n",
    "# name = 'system_active_memory'\n",
    "# quant_df = df.quantile([low, high])\n",
    "# print(quant_df.loc[low, name], quant_df.loc[high, name])\n",
    "# np.average(new_data[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove the outlier from the whole dataset\n",
    "# def remove_outlier(df):\n",
    "#     low = .25\n",
    "#     high = .75\n",
    "#     quant_df = df.quantile([low, high])\n",
    "#     for name in list(df.columns):\n",
    "#         if is_numeric_dtype(df[name]):\n",
    "#             df[name] = df[(df[name] > quant_df.loc[low, name]) & (df[name] < quant_df.loc[high, name])]\n",
    "#     return df\n",
    "\n",
    "# df= remove_outlier(new_data)\n",
    "# plt.figure(figsize=(15,7))\n",
    "# plt.xticks(rotation='vertical')\n",
    "# s = df.boxplot()\n",
    "# s.set_xticklabels(df.columns,rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['system_active_memory'], final_df['system_active_memory']\n",
    "# for col in new_data.columns:\n",
    "#     if new_data[col].isna():\n",
    "#         new_data.drop(columns=col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.average(new_data['Cpu Working Time_fe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# wcss = []\n",
    "\n",
    "# X = np.array(new_data)\n",
    "\n",
    "# for i in range(1, 11):\n",
    "#     kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
    "#     kmeans.fit(X.reshape(-1,1))\n",
    "#     wcss.append(kmeans.inertia_)\n",
    "# plt.plot(range(1, 11), wcss)\n",
    "# plt.title('The Elbow Method')\n",
    "# plt.xlabel('Number of clusters')\n",
    "# plt.ylabel('WCSS')\n",
    "# plt.show()\n",
    "\n",
    "# kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)\n",
    "# y_kmeans = kmeans.fit_predict(new_data)\n",
    "# new_data['y'] = y_kmeans\n",
    "\n",
    "# sb.countplot(x=y_kmeans, data=new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# cor = new_data.corr() #Calculate the correlation of the above variables\n",
    "# sb.heatmap(cor, square = True) #Plot the correlation as heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cluster = final_df\n",
    "# df_cluster.shape, final_df.shape\n",
    "# d = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 42)\n",
    "# y_kmeans = kmeans.fit_predict(final_df)\n",
    "# final_df['y'] = y_kmeans\n",
    "\n",
    "# sb.countplot(x=y_kmeans, data=final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# sb.heatmap(final_df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,8))\n",
    "# sb.boxplot(data=final_df)\n",
    "# plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import important libraries.\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from pandas.api.types import is_numeric_dtype\n",
    "# import seaborn as sns\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, accuracy_score\n",
    "# def remove_outlier(df):\n",
    "#     low = .25\n",
    "#     high = .75\n",
    "#     quant_df = df.quantile([low, high])\n",
    "#     for name in list(df.columns):\n",
    "#         if is_numeric_dtype(df[name]):\n",
    "#             df = df[(df[name] > quant_df.loc[low, name]) & (df[name] < quant_df.loc[high, name])]\n",
    "#     return df\n",
    "\n",
    "# df= remove_outlier(final_df)\n",
    "# sns.boxplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in final_df.columns:\n",
    "# #     plt.hist(x=col)\n",
    "#     sb.distplot(final_df[col])\n",
    "#     plt.xticks(rotation=90)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # No Feature Scaling as library does it\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc_X = StandardScaler()\n",
    "# X = sc_X.fit_transform(final_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# wcss = []\n",
    "# X = np.array(final_df)\n",
    "\n",
    "# for i in range(1, 11):\n",
    "#     kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
    "#     kmeans.fit(X)\n",
    "#     wcss.append(kmeans.inertia_)\n",
    "# plt.plot(range(1, 11), wcss)\n",
    "# plt.title('The Elbow Method')\n",
    "# plt.xlabel('Number of clusters')\n",
    "# plt.ylabel('WCSS')\n",
    "# plt.show()\n",
    "\n",
    "# kmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 42)\n",
    "# y_kmeans = kmeans.fit_predict(final_df)\n",
    "# final_df['y'] = y_kmeans\n",
    "\n",
    "# sb.countplot(x=y_kmeans, data=final_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
